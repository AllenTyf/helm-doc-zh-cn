{"./":{"url":"./","title":"序言","keywords":"","body":"Helm User Guide - Helm 用户指南 本指南是官方Kubernetes的github库下，helm子目录下的文档的翻译，依照 https://docs.helm.sh/ 的文档架构和组织，当前翻译了第一部分的用户指南部分，后续会陆续更新，用于给刚接触Helm这个工具的朋友一个指导手册。由于Gitbook不支持花括弧，所以临时处理了一下，会持续更新（如果有朋友知道如何更好的在gitbook里面处理花括弧，欢迎告知我）！！ 目录 前言 序言 用户指南 快速入门 安装 Kubernetes各发行版Helm 安装FAQ 使用 插件 RBAC 安全安装 Helm命令参考 Charts Charts Hooks 开发模板 最佳实践 相关项目和文档 Kubernetes Helm 架构 开发指南 项目历史 术语表 何处寻找Charts Copyright © Mingo 2017-2018 all right reserved，powered by GitbookUpdated at 2018-04-30 18:26:34 "},"quickstart/quickstart-zh_cn.html":{"url":"quickstart/quickstart-zh_cn.html","title":"快速入门","keywords":"","body":"快速入门 本指南介绍如何快速开始使用Helm。 前提条件 需要以下前提条件才能正常且安全地使用Helm。 一个Kubernetes集群 确定使用哪种安装安全配置（如果有的话） 安装和配置Helm和Tiller（集群端服务）。 安装Kubernetes或有权访问群集 必须已安装Kubernetes。对于Helm的最新版本，我们推荐最新的Kubernetes稳定版本，在大多数情况下它是次新版本。 应该有一个本地配置好的kubectl。 主意：1.6之前的Kubernetes版本对于基于角色的访问控制（RBAC），要么有限制，或者不支持。 Helm将通过Kubernetes配置文件（通常是$HOME/.kube/config）来确定在哪里安装Tiller 。这个配置文件也是kubectl使用的文件。 要找出Tiller将安装到哪个集群，可以运行 kubectl config current-context或kubectl cluster-info。 $ kubectl config current-context my-cluster 了解集群配置的安全上下文 与所有强大的工具一样，需要确保在环境里正确安装。 如果你在完全控制的群集上使用Helm，如minikube或专用网络中的不考虑共享的群集，则默认安装（不采用安全配置）很合适，并且是最容易的。要在无需额外安全措施的场景下安装Helm，请参考安装Helm，然后初始化Helm。 但是，如果集群暴露于更大的网络中，或者集群与他人共享 - 生产集群属于此类别 - 则必须采取额外步骤来确保安装安全，以防止不小心或恶意的操作者损坏集群或其集群数据。在生产环境和其他多租户方案中，要使用安全配置安装Helm，请参阅Helm安全安装。 如果群集启用了基于角色的访问控制（RBAC），在继续之前配置服务帐户(service account)和规则。 安装Helm 下载Helm客户端的二进制版本。可以使用类似工具如homebrew，或查看官方版本页面。 有关更多详细信息或其他选项，请参阅安装指南。 初始化Helm并安装Tiller 有了Helm安装文件，就可以初始化本地CLI，并将Tiller安装到Kubernetes集群中： $ helm init 这会将Tiller安装到对应的Kubernetes群集中,集群同kubectl config current-context。 提示： 想要安装到不同的群集中？使用该 --kube-context 参数。 提示： 如果要升级Tiller，请运行helm init --upgrade。 默认情况下，安装Tiller时，没有启用身份验证。要了解有关为Tiller配置增强TLS身份验证的更多信息，请参阅 Tiller TLS指南。 安装示例Chart 要安装一个chart，您可以运行helm install命令。Helm有几种方法来查找和安装chart，但最简单的方法是使用其中一个官方stable稳定版本的chart。 $ helm repo update ＃确保我们获得最新的chart列表 $ helm install stable / mysql Released smile-penguin 在上面的例子中，stable/mysql 已经安装，安装版本的release的名字是smiling-penguin。通过运行helm inspect stable/mysql可以简单了解该MySQL chart的功能。 无论何时安装chart，都会创建一个新release版本。所以一个chart可以多次安装到同一个群集中。而且每个都可以独立管理和升级。 helm install命令功能非常丰富，具有很多强大功能。要了解更多信息，请查看使用Helm指南 了解安装的release 很容易通过如下命令查看已使用Helm安装的内容： $ helm ls NAME VERSION UPDATED STATUS CHART smiling-penguin 1 Wed Sep 28 12:59:46 2016 DEPLOYED mysql-0.1.0 卸载安装的release 要卸载安装的release，请使用以下helm delete命令： $ helm delete smiling-penguin Removed smiling-penguin smiling-penguin release将从Kubernetes 卸载，但仍然可以查询有关该release的信息： $ helm status smiling-penguin Status: DELETED ... 由于Helm在删除它们之后也会跟踪release，因此可以审核群集的历史记录，甚至可以取消删除动作（使用helm rollback）。 阅读帮助文本 要了解有关Helm命令的更多信息，请使用helm help或键入一个后跟该-h标志的命令： $ helm get -h Copyright © Mingo 2017-2018 all right reserved，powered by GitbookUpdated at 2018-04-30 18:43:39 "},"quickstart/install-zh_cn.html":{"url":"quickstart/install-zh_cn.html","title":"安装","keywords":"","body":"安装 Helm有两个部分：Helm客户端（helm）和Helm服务器（Tiller）。本指南介绍如何安装客户端，然后继续演示两种安装服务端的方法。 重要提示：如果你负责的群集是在受控的环境，尤其是在共享资源时，强烈建议使用安全配置安装Tiller。有关指导，请参阅安全Helm安装。 安装Helm客户端 Helm客户端可以从源代码安装，也可以从预构建的二进制版本安装。 二进制版本 每一个版本releaseHelm提供多种操作系统的二进制版本。这些二进制版本可以手动下载和安装。 下载你想要的版本 解压缩（tar -zxvf helm-v2.0.0-linux-amd64.tgz） helm在解压后的目录中找到二进制文件，并将其移动到所需的位置（mv linux-amd64/helm /usr/local/bin/helm） 到这里，你应该可以运行客户端了：helm help。 通过homebrew（macOS） Kubernetes社区的成员为Homebrew贡献了Helm。这个通常是最新的。 brew install kubernetes-helm （注意：emacs-helm也是一个软件，这是一个不同的项目。） 从Chocolatey（Windows） Kubernetes社区的成员为 Chocolatey贡献了Helm包。这个软件包通常是最新的。 choco install kubernetes-helm 从脚本 Helm现在有一个安装shell脚本，将自动获取最新版本的Helm客户端并在本地安装。 可以获取该脚本，然后在本地执行它。这种方法也有文档指导，以便可以在运行之前仔细阅读并理解它在做什么。 $ curl https://raw.githubusercontent.com/kubernetes/helm/master/scripts/get > get_helm.sh $ chmod 700 get_helm.sh $ ./get_helm.sh curl https://raw.githubusercontent.com/kubernetes/helm/master/scripts/get | bash 也可以做到这一点。 从金丝雀(Canary )构建 “Canary”版本是从最新的主分支构建的Helm软件的版本。它们不是正式版本，可能不稳定。但是，他们提供了测试最新功能的机会。 \"Canary\"版本Helm二进制文件存储在Kubernetes Helm GCS存储中。以下是常见构建的链接： Linux AMD64 macOS AMD64 Experimental Windows AMD64 源代码方式（Linux，macOS） 从源代码构建Helm的工作稍微多一些，但如果你想测试最新的（预发布）Helm版本，那么这是最好的方法。 你必须有一个安装Go工作环境 。 $ cd $GOPATH $ mkdir -p src/k8s.io $ cd src/k8s.io $ git clone https://github.com/kubernetes/helm.git $ cd helm $ make bootstrap build 该bootstrap目标将尝试安装依赖，重建 vendor/树，并验证配置。 该build目标编译helm并将其放置在bin/helm目录。Tiller也会编译，并且被放置在bin/tiller目录。 安装Tiller Helm的服务器端部分Tiller通常运行在Kubernetes集群内部。但是对于开发，它也可以在本地运行，并配置为与远程Kubernetes群集通信。 快捷群集内安装 安装tiller到群集中最简单的方法就是运行 helm init。这将验证helm本地环境设置是否正确（并在必要时进行设置）。然后它会连接到kubectl默认连接的任何集群（kubectl config view）。一旦连接，它将安装tiller到 kube-system命名空间中。 helm init以后，可以运行kubectl get pods --namespace kube-system并看到Tiller正在运行。 你可以通过参数运行helm init: --canary-image 参数安装金丝雀版本 --tiller-image 安装特定的镜像（版本） --kube-context 使用安装到特定群集 --tiller-namespace 用一个特定的命名空间(namespace)安装 一旦安装了Tiller，运行helm version会显示客户端和服务器版本。（如果它仅显示客户端版本， helm则无法连接到服务器,使用kubectl查看是否有任何 tiller Pod正在运行。） 除非设置--tiller-namespace或TILLER_NAMESPACE参数，否则Helm将在命名空间kube-system中查找Tiller 。 安装Tiller金丝雀版本 Canary 镜像是从master分支建立的。他们可能不稳定，但他们为您提供测试最新功能的机会。 安装Canary 镜像最简单的方法是helm init与 --canary-image参数一起使用： $ helm init --canary-image 这将使用最近构建的容器镜像。您可以随时使用kubectl删除kube-system名称空间中的Tiller deployment来卸载Tiller。 本地运行Tiller 对于开发而言，有时在本地运行Tiller更容易，将其配置为连接到远程Kubernetes群集。 上面介绍了构建部署Tiller的过程。 一旦tiller构建部署完成，只需启动它： $ bin/tiller Tiller running on :44134 当Tiller在本地运行时，它将尝试连接到由kubectl配置的Kubernetes群集。（运行kubectl config view以查看是哪个群集。） 必须告知helm连接到这个新的本地Tiller主机，而不是连接到群集中的一个。有两种方法可以做到这一点。第一种是在命令行上指定--host选项。第二个是设置$HELM_HOST环境变量。 $ export HELM_HOST=localhost:44134 $ helm version # Should connect to localhost. Client: &version.Version{SemVer:\"v2.0.0-alpha.4\", GitCommit:\"db...\", GitTreeState:\"dirty\"} Server: &version.Version{SemVer:\"v2.0.0-alpha.4\", GitCommit:\"a5...\", GitTreeState:\"dirty\"} 注意，即使在本地运行，Tiller也会将安装的release配置存储在Kubernetes内的ConfigMaps中。 升级Tiller 从Helm 2.2.0开始，Tiller可以升级使用helm init --upgrade。 对于旧版本的Helm或手动升级，可以使用kubectl修改Tiller容器镜像： $ export TILLER_TAG=v2.0.0-beta.1 # Or whatever version you want $ kubectl --namespace=kube-system set image deployments/tiller-deploy tiller=gcr.io/kubernetes-helm/tiller:$TILLER_TAG deployment \"tiller-deploy\" image updated 设置TILLER_TAG=canary将获得master版本的最新快照。 删除或重新安装Tiller 由于Tiller将其数据存储在Kubernetes ConfigMaps中，因此可以安全地删除并重新安装Tiller，而无需担心丢失任何数据。推荐删除Tiller的方法是使用kubectl delete deployment tiller-deploy --namespace kube-system或更简洁使用helm reset。 然后可以从客户端重新安装Tiller： $ helm init 高级用法 helm init 提供了额外的参数，用于在安装之前修改Tiller的deployment manifest。 使用 --node-selectors --node-selectors参数允许我们指定调度Tiller Pod所需的节点标签。 下面的例子将在nodeSelector属性下创建指定的标签。 helm init --node-selectors \"beta.kubernetes.io/os\"=\"linux\" 已安装的deployment manifest将包含我们的节点选择器标签。 ... spec: template: spec: nodeSelector: beta.kubernetes.io/os: linux ... 使用 --override --override允许指定Tiller的deployment manifest的属性。与在Helm其他地方--set使用的命令不同，helm init --override修改最终manifest的指定属性（没有\"values\"文件）。因此，可以为deployment manifest中的任何有效属性指定任何有效值。 覆盖注释 在下面的示例中，我们使用--override添加修订版本属性并将其值设置为1。 helm init --override metadata.annotations.\"deployment\\.kubernetes\\.io/revision\"=\"1\" 输出： apiVersion: extensions/v1beta1 kind: Deployment metadata: annotations: deployment.kubernetes.io/revision: \"1\" ... 覆盖亲和性 在下面的例子中，我们为节点设置了亲和性属性。--override可以组合来修改同一列表项的不同属性。 helm init --override \"spec.template.spec.affinity.nodeAffinity.preferredDuringSchedulingIgnoredDuringExecution[0].weight\"=\"1\" --override \"spec.template.spec.affinity.nodeAffinity.preferredDuringSchedulingIgnoredDuringExecution[0].preference.matchExpressions[0].key\"=\"e2e-az-name\" 指定的属性组合到“preferredDuringSchedulingIgnoredDuringExecution”属性的第一个列表项中。 ... spec: strategy: {} template: ... spec: affinity: nodeAffinity: preferredDuringSchedulingIgnoredDuringExecution: - preference: matchExpressions: - key: e2e-az-name operator: \"\" weight: 1 ... 使用 --output --output参数允许我们跳过安装Tiller的deployment manifest，并以JSON或YAML格式简单地将deployment manifest输出到标准输出stdout。然后可以使用jq类似工具修改输出，并使用kubectl手动安装。 在下面的例子中，我们helm init用--output json 参数执行。 helm init --output json Tiller安装被跳过，manifest以JSON格式输出到stdout。 \"apiVersion\": \"extensions/v1beta1\", \"kind\": \"Deployment\", \"metadata\": { \"creationTimestamp\": null, \"labels\": { \"app\": \"helm\", \"name\": \"tiller\" }, \"name\": \"tiller-deploy\", \"namespace\": \"kube-system\" }, ... 存储后端 默认情况下，tiller将安装release信息存储在其运行的名称空间中的ConfigMaps中。从Helm 2.7.0开始，现在有一个Secrets用于存储安装release信息的beta存储后端。添加了这个功能是为和Kubernetes的加密Secret一起，保护chart的安全性。 要启用secrets后端，需要使用以下选项启动Tiller： helm init --override 'spec.template.spec.containers[0].command'='{/tiller,--storage=secret}' 目前，如果您想从默认后端切换到secrets后端，必须自行为此进行迁移配置信息。当这个后端从beta版本毕业时，将会有更正式的移徙方法。 总结 在大多数情况下，安装和获取预先构建的helm二进制代码及helm init一样简单。这个文档提供而了一些用例给那些想要用Helm做更复杂的事情的人。 一旦成功安装了Helm Client和Tiller，可以继续下一步使用Helm来管理charts。 Copyright © Mingo 2017-2018 all right reserved，powered by GitbookUpdated at 2018-04-30 18:44:20 "},"quickstart/kubernetes_distros-zh_cn.html":{"url":"quickstart/kubernetes_distros-zh_cn.html","title":"Kubernetes各发行版Helm","keywords":"","body":"Kubernetes各发行版本指南 本文档描述有关在各Kubernetes发行版本环境中使用Helm的信息。 我们尝试为此文档添加更多详细信息。如果可以，请通过Pull Requests提供。 MiniKube Helm已经过测试并且已知可以与minikube一起使用。它不需要额外的配置。 scripts/local-cluster 和Hyperkube 通过配置Hyperkube scripts/local-cluster.sh已知可以工作。对于原始的Hyperkube，可能需要进行一些手动配置。 GKE 已知Google的GKE托管Kubernetes平台与Helm一起工作，并且不需要额外的配置。 Ubuntu与'kubeadm' kubeadm构建的Kubernetes已知可用于以下Linux发行版： Ubuntu 16.04 Fedora发布25 某些版本的Helm（v2.0.0-beta2）要求export KUBECONFIG=/etc/kubernetes/admin.conf 或创建一个~/.kube/config文件。 CoreOS提供的Container Linux Helm要求kubelet可以访问socat程序的副本，以代理与Tiller API的连接。在Container Linux上，Kubelet在具有socat 的hyperkube 容器映像中运行。因此，尽管Container Linux没有socat,运行kubelet的容器​​文件系统具有socat。要了解更多信息，请阅读Kubelet Wrapper 文档。 Openshift Helm可在OpenShift Online，OpenShift Dedicated，OpenShift Container Platform（版本> = 3.6）或OpenShift Origin（版本> = 3.6）中直接使用。要了解更多，请阅读此博客文章。 Platform9 Helm Client和Helm Server（Tiller）预装在Platform9 Managed Kubernetes。Platform9通过App目录UI和本地Kubernetes CLI提供对所有官方Helm charts的访问。其他repo存储库可以手动添加。有关更多详细信息，请参阅Platform9 App Catalog文章。 DC / OS Helm（客户端和服务器）已经过测试，在Mesospheres DC / OS 1.11 Kubernetes平台工作正常，无需其他配置。 Copyright © Mingo 2017-2018 all right reserved，powered by GitbookUpdated at 2018-04-28 22:42:25 "},"quickstart/install_faq-zh_cn.html":{"url":"quickstart/install_faq-zh_cn.html","title":"安装FAQ","keywords":"","body":"安装FAQ 本节跟踪安装或开始使用Helm时遇到的一些经常遇到的问题。 欢迎你的帮助 来更好的提供此文档。要添加，更正或删除信息，提出问题issue或向我们发送PR请求。 下载 我想知道更多关于我的下载选项。 问：我无法获得最新Helm的GitHub发布。他们在哪？ 答：我们不再使用GitHub发布版本。二进制文件现在存储在 GCS公共存储区中GCS public bucket。 问：为什么没有Debian/Fedora/... Helm的原生的软件包？ 我们很乐意提供这些信息，或者指向可靠的提供商。如果你对帮助感兴趣，我们很乐意。这就是Homebrew式的开始。 问：你为什么要提供一个curl ...|bash脚本？ 答：我们的repo库（scripts/get）中有一个脚本可以作为curl ..|bash脚本执行。这些传输全部受HTTPS保护，并且脚本会对其获取的包进行一些审计。但是，脚本具有任何shell脚本的所有常见危险。 我们提供它是因为它很有用，但我们建议用户先仔细阅读脚本。并且，我们真正喜欢的是Helm的的打包版本。 安装 我正在尝试安装Helm/Tiller，但有些地方出了问题。 问：我如何将Helm客户端文件放在~/.helm以外的地方？ 设置$HELM_HOME环境变量，然后运行helm init： export HELM_HOME=/some/path helm init --client-only 注意，如果你有现有的repo存储库，则需要通过helm repo add....重新添加它们。 问：我如何配置Helm，但不安装Tiller？ 答：默认情况下，helm init将确认本​​地$HELM_HOME配置，然后在群集上安装Tiller。要本地配置，但不安装Tiller，请使用helm init --client-only。 问：如何在集群上手动安装Tiller？ 答：Tiller是作为Kubernetes deployment安装的。您可以通过运行helm init --dry-run --debug获取manifest，然后通过kubectl手动安装 。建议不要删除或更改该deployment中的标签labels，因为它们有时支持脚本和工具需要用到。 问：为什么安装Tiller期间报错误Error response from daemon: target is unknown？ 答：有用户报告无法在使用Docker 1.13.0的Kubernetes实例上安装Tiller。造成这种情况的根本原因是Docker中的一个错误，它使得一个版本与早期版本的Docker推送到Docker注册表的镜像不兼容。 该问题在发布后不久就已修复，并在Docker 1.13.1-RC1和更高版本中提供。 入门 我成功安装了Helm/Tiller，但我使用时碰到问题。 问：使用Helm时，收到错误“客户端传输中断” E1014 02:26:32.885226 16143 portforward.go:329] an error occurred forwarding 37008 -> 44134: error forwarding port 44134 to pod tiller-deploy-2117266891-e4lev_kube-system, uid : unable to do port forwarding: socat not found. 2016/10/14 02:26:32 transport: http2Client.notifyError got notified that the client transport was broken EOF. Error: transport is closing 答：这通常表明Kubernetes未设置为允许端口转发。 通常情况下，缺少的部分是socat。如果您正在运行CoreOS，我们被告知它可能在安装时配置错误。CoreOS团队建议阅读以下内容： https://coreos.com/kubernetes/docs/latest/kubelet-wrapper.html 以下是一些解决的问题案例，可以帮助您开始使用： https://github.com/kubernetes/helm/issues/1371 https://github.com/kubernetes/helm/issues/966 Q：使用Helm时,报错误\"lookup XXXXX on 8.8.8.8:53: no such host\" Error: Error forwarding ports: error upgrading connection: dial tcp: lookup kube-4gb-lon1-02 on 8.8.8.8:53: no such host 答：我们在Ubuntu和Kubeadm多节点群集中有这个问题。问题原因是节点期望某些DNS记录可以通过全局DNS获得。在上游解决此问题之前，可以按照以下方式解决该问题。在每个控制平面节点上： 添加条目到/etc/hosts，将主机名映射到其 public IP 安装dnsmasq（例如apt install -y dnsmasq） 删除k8s api服务容器（kubelet会重新创建它） 然后systemctl restart docker（或重新启动节点）请/etc/resolv.conf更改 请参阅此问题以获取更多信息：https://github.com/kubernetes/helm/issues/1455 问：在GKE（Google Container Engine）上，报错\"No SSH tunnels currently open\" Error: Error forwarding ports: error upgrading connection: No SSH tunnels currently open. Were the targets able to accept an ssh-key for user \"gke-[redacted]\"? 错误消息的另一个形式是： Unable to connect to the server: x509: certificate signed by unknown authority 答：这个问题是你的本地Kubernetes配置文件必须具有正确的凭据。 在GKE上创建集群时，它将提供凭证，包括SSL证书和证书颁发机构信息。这些需要存储在一个Kubernetes配置文件中（默认：~/.kube/config，这样kubectl和helm可以访问它们）。 问：当我运行Helm命令时，出现有关隧道tunnel或代理proxy的错误 答：Helm使用Kubernetes代理服务连接到Tiller服务器。如果命令kubectl proxy不适用，Helm也不行。通常，错误与缺失的socat服务有关。 问：Tiller 崩溃 当我在Helm上运行命令时，Tiller崩溃时会出现如下错误： Tiller is listening on :44134 Probes server is listening on :44135 Storage driver is ConfigMap Cannot initialize Kubernetes connection: the server has asked for the client to provide credentials 2016-12-20 15:18:40.545739 I | storage.go:37: Getting release \"bailing-chinchilla\" (v1) from storage panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x8053d5] goroutine 77 [running]: panic(0x1abbfc0, 0xc42000a040) /usr/local/go/src/runtime/panic.go:500 +0x1a1 k8s.io/helm/vendor/k8s.io/kubernetes/pkg/client/unversioned.(*ConfigMaps).Get(0xc4200c6200, 0xc420536100, 0x15, 0x1ca7431, 0x6, 0xc42016b6a0) /home/ubuntu/.go_workspace/src/k8s.io/helm/vendor/k8s.io/kubernetes/pkg/client/unversioned/configmap.go:58 +0x75 k8s.io/helm/pkg/storage/driver.(*ConfigMaps).Get(0xc4201d6190, 0xc420536100, 0x15, 0xc420536100, 0x15, 0xc4205360c0) /home/ubuntu/.go_workspace/src/k8s.io/helm/pkg/storage/driver/cfgmaps.go:69 +0x62 k8s.io/helm/pkg/storage.(*Storage).Get(0xc4201d61a0, 0xc4205360c0, 0x12, 0xc400000001, 0x12, 0x0, 0xc420200070) /home/ubuntu/.go_workspace/src/k8s.io/helm/pkg/storage/storage.go:38 +0x160 k8s.io/helm/pkg/tiller.(*ReleaseServer).uniqName(0xc42002a000, 0x0, 0x0, 0xc42016b800, 0xd66a13, 0xc42055a040, 0xc420558050, 0xc420122001) /home/ubuntu/.go_workspace/src/k8s.io/helm/pkg/tiller/release_server.go:577 +0xd7 k8s.io/helm/pkg/tiller.(*ReleaseServer).prepareRelease(0xc42002a000, 0xc42027c1e0, 0xc42002a001, 0xc42016bad0, 0xc42016ba08) /home/ubuntu/.go_workspace/src/k8s.io/helm/pkg/tiller/release_server.go:630 +0x71 k8s.io/helm/pkg/tiller.(*ReleaseServer).InstallRelease(0xc42002a000, 0x7f284c434068, 0xc420250c00, 0xc42027c1e0, 0x0, 0x31a9, 0x31a9) /home/ubuntu/.go_workspace/src/k8s.io/helm/pkg/tiller/release_server.go:604 +0x78 k8s.io/helm/pkg/proto/hapi/services._ReleaseService_InstallRelease_Handler(0x1c51f80, 0xc42002a000, 0x7f284c434068, 0xc420250c00, 0xc42027c190, 0x0, 0x0, 0x0, 0x0, 0x0) /home/ubuntu/.go_workspace/src/k8s.io/helm/pkg/proto/hapi/services/tiller.pb.go:747 +0x27d k8s.io/helm/vendor/google.golang.org/grpc.(*Server).processUnaryRPC(0xc4202f3ea0, 0x28610a0, 0xc420078000, 0xc420264690, 0xc420166150, 0x288cbe8, 0xc420250bd0, 0x0, 0x0) /home/ubuntu/.go_workspace/src/k8s.io/helm/vendor/google.golang.org/grpc/server.go:608 +0xc50 k8s.io/helm/vendor/google.golang.org/grpc.(*Server).handleStream(0xc4202f3ea0, 0x28610a0, 0xc420078000, 0xc420264690, 0xc420250bd0) /home/ubuntu/.go_workspace/src/k8s.io/helm/vendor/google.golang.org/grpc/server.go:766 +0x6b0 k8s.io/helm/vendor/google.golang.org/grpc.(*Server).serveStreams.func1.1(0xc420124710, 0xc4202f3ea0, 0x28610a0, 0xc420078000, 0xc420264690) /home/ubuntu/.go_workspace/src/k8s.io/helm/vendor/google.golang.org/grpc/server.go:419 +0xab created by k8s.io/helm/vendor/google.golang.org/grpc.(*Server).serveStreams.func1 /home/ubuntu/.go_workspace/src/k8s.io/helm/vendor/google.golang.org/grpc/server.go:420 +0xa3 答：请检查Kubernetes的安全设置。 Tiller中的崩溃几乎总是由于未能与Kubernetes API服务器进行协商而导致的结果（此时，Tiller功能不正常，因此崩溃并退出）。 通常，这是认证失败的结果，因为运行Tiller的Pod没有正确的令牌token。 要解决这个问题，你需要修改Kubernetes配置。确保--service-account-private-key-file从controller-manager和 --service-account-key-file从API服务器指向同一个X509 RSA密钥。 升级 我的Helm原来工作正常，然后我升级了。现在它工作不正常。 问：升级后，我收到错误“Client version is incompatible”。怎么问题？ Tiller和Helm必须协商一个通用版本，以确保他们可以安全地进行通信而不会违反API假设。该错误意味着版本差异太大而无法安全地继续。通常，需要为此手动升级Tiller。 该安装指南Installation Guide大约有安全Helm升级和Tiller权威信息。 版本号的规则如下： 预发布版本与其他一切不兼容。Alpha.1与...不相容Alpha.2。 修补程序版本兼容：1.2.3与1.2.4兼容 少量修订不兼容：1.2.0与1.3.0不兼容，但我们可能在未来放宽这一限制。 主要版本不兼容：1.0.0与2.0.0不兼容。 卸载 我正在尝试删除某些东西。 问：当我删除Tiller deployment时，为何所有安装的release信息还在集群里？ 安装release信息存储在kube-system名称空间内的ConfigMaps中。需要手动删除它们以删除记录或使用helm delete --purge。 问：我想删除我的本地Helm。它的所有文件在哪里？ 包括helm二进制文件，Helm存储了一些文件在$HELM_HOME，默认位于~/.helm。 Copyright © Mingo 2017-2018 all right reserved，powered by GitbookUpdated at 2018-04-30 18:43:39 "},"quickstart/using_helm-zh_cn.html":{"url":"quickstart/using_helm-zh_cn.html","title":"使用","keywords":"","body":"使用 本指南讲述使用Helm（和Tiller）来管理Kubernetes群集上的软件包的基础知识。前提是假定你已经安装了Helm客户端和Tiller服务端（通常通过helm init）。 如果只是想运行一些简单命令，可以从快速入门指南开始。本章将介绍Helm命令的具体内容，并解释如何使用Helm。 三大概念 A Chart 是一个Helm包。它包含在Kubernetes集群内部运行应用程序，工具或服务所需的所有资源定义。把它想像为一个自制软件，一个Apt dpkg或一个Yum RPM文件的Kubernetes环境里面的等价物。 A Repository 是Charts收集和共享的地方。它就像Perl的CPAN archive或Fedora软件包repoFedora Package Database。 A Release 是处于Kubernetes集群中运行的Chart的一个实例。一个chart通常可以多次安装到同一个群集中。每次安装时，都会创建一个新 release 。比如像一个MySQL chart。如果希望在群集中运行两个数据库，则可以安装该chart两次。每个都有自己的 release，每个 release 都有自己的 release name。 有了这些概念，我们现在可以这样解释Helm： Helm将 charts 安装到Kubernetes中，每个安装创建一个新 release 。要找到新的chart，可以搜索Helm charts 存储库 repositories。 'helm search':查找Charts 首次安装Helm时，它已预配置为与官方Kubernetes chart 存储库repo。该repo包含许多精心策划和维护的charts。此charts repo默认以stable命名。 您可以通过运行helm search查看哪些charts可用： $ helm search NAME VERSION DESCRIPTION stable/drupal 0.3.2 One of the most versatile open source content m... stable/jenkins 0.1.0 A Jenkins Helm chart for Kubernetes. stable/mariadb 0.5.1 Chart for MariaDB stable/mysql 0.1.0 Chart for MySQL ... 如果没有使用过滤，helm search显示所有可用的charts。可以通过使用过滤器进行搜索来缩小搜索结果范围： $ helm search mysql NAME VERSION DESCRIPTION stable/mysql 0.1.0 Chart for MySQL stable/mariadb 0.5.1 Chart for MariaDB 现在只会看到过滤器匹配的结果。 为什么mariadb在列表中？因为它的包描述与MySQL相关。我们可以使用helm inspect chart到这个： $ helm inspect stable/mariadb Fetched stable/mariadb to mariadb-0.5.1.tgz description: Chart for MariaDB engine: gotpl home: https://mariadb.org keywords: - mariadb - mysql - database - sql ... 搜索是找到可用软件包的好方法。一旦找到想要安装的软件包，可以使用helm install它来安装它。 'helm install'：安装一个软件包 要安装新的软件包，请使用该helm install命令。最简单的方法，它只需要一个参数：chart的名称。 $ helm install stable/mariadb Fetched stable/mariadb-0.3.0 to /Users/mattbutcher/Code/Go/src/k8s.io/helm/mariadb-0.3.0.tgz happy-panda Last Deployed: Wed Sep 28 12:32:28 2016 Namespace: default Status: DEPLOYED Resources: ==> extensions/Deployment NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE happy-panda-mariadb 1 0 0 0 1s ==> v1/Secret NAME TYPE DATA AGE happy-panda-mariadb Opaque 2 1s ==> v1/Service NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE happy-panda-mariadb 10.0.0.70 3306/TCP 1s Notes: MariaDB can be accessed via port 3306 on the following DNS name from within your cluster: happy-panda-mariadb.default.svc.cluster.local To connect to your database run the following command: kubectl run happy-panda-mariadb-client --rm --tty -i --image bitnami/mariadb --command -- mysql -h happy-panda-mariadb 当mariadb chart已安装，请注意，安装chart会创建一个新 release 对象。上面的release被命名 为happy-panda。（如果你想使用你自己的release名称，只需使用 --name 参数 配合helm install。） 在安装过程中，helm客户端将打印有关创建哪些资源的有用信息，release的状态以及是否可以或应该采取其他的配置步骤。 Helm不会一直等到所有资源都运行才退出。许多charts需要大小超过600M的Docker 镜像，并且可能需要很长时间才能安装到群集中。 要跟踪release状态或重新读取配置信息，可以使用helm status： $ helm status happy-panda Last Deployed: Wed Sep 28 12:32:28 2016 Namespace: default Status: DEPLOYED Resources: ==> v1/Service NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE happy-panda-mariadb 10.0.0.70 3306/TCP 4m ==> extensions/Deployment NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE happy-panda-mariadb 1 1 1 1 4m ==> v1/Secret NAME TYPE DATA AGE happy-panda-mariadb Opaque 2 4m Notes: MariaDB can be accessed via port 3306 on the following DNS name from within your cluster: happy-panda-mariadb.default.svc.cluster.local To connect to your database run the following command: kubectl run happy-panda-mariadb-client --rm --tty -i --image bitnami/mariadb --command -- mysql -h happy-panda-mariadb 以上显示了release的当前状态。 在安装前自定义chart 上面的安装方式使用chart的默认配置选项。很多时候，我们需要自定义chart以使用自定义配置。 要查看chart上可配置的选项，请使用helm inspect values： helm inspect values stable/mariadb Fetched stable/mariadb-0.3.0.tgz to /Users/mattbutcher/Code/Go/src/k8s.io/helm/mariadb-0.3.0.tgz ## Bitnami MariaDB image version ## ref: https://hub.docker.com/r/bitnami/mariadb/tags/ ## ## Default: none imageTag: 10.1.14-r3 ## Specify a imagePullPolicy ## Default to 'Always' if imageTag is 'latest', else set to 'IfNotPresent' ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images ## # imagePullPolicy: ## Specify password for root user ## ref: https://github.com/bitnami/bitnami-docker-mariadb/blob/master/README.md#setting-the-root-password-on-first-run ## # mariadbRootPassword: ## Create a database user ## ref: https://github.com/bitnami/bitnami-docker-mariadb/blob/master/README.md#creating-a-database-user-on-first-run ## # mariadbUser: # mariadbPassword: ## Create a database ## ref: https://github.com/bitnami/bitnami-docker-mariadb/blob/master/README.md#creating-a-database-on-first-run ## # mariadbDatabase: 然后，可以在YAML格式的文件中覆盖任何这些设置，然后在安装过程中传递该文件。 $ echo '{mariadbUser: user0, mariadbDatabase: user0db}' > config.yaml $ helm install -f config.yaml stable/mariadb 以上将创建一个名称为MariaDB的默认用户user0，并授予此用户对新创建user0db数据库的访问权限，其他使用该chart的默认值。 在安装过程中有两种方式传递自定义配置数据： --values（或-f）：指定一个overrides的YAML文件。可以指定多次，最右边的文件将优先使用 --set：在命令行上指定overrides。 如果两者都使用，则将--set值合并到--values更高的优先级中。指定的override --set将保存在configmap中。--set可以通过使用特定的版本查看已经存在的值 helm get values ,--set设置的值可以通过运行helm upgrade与--reset-values 重置。 --set格式和限制 --set选项使用零个或多个name/value对。最简单的用法：--set name=value。YAML体现是： name: value 多个值由,字符分隔。因此--set a=b,c=d变成： a: b c: d 支持更复杂的表达式。例如，--set outer.inner=value变成这样： outer: inner: value 列表可以通过在{和}中包含值来表示。例如， --set name={a, b, c}转化为： name: - a - b - c 从Helm 2.5.0开始，可以使用数组索引语法访问列表项。例如，--set servers[0].port=80变成： servers: - port: 80 可以通过这种方式设置多个值。该行--set servers[0].port=80,servers[0].host=example变成： servers: - port: 80 host: example 有时候你需要在--set行中使用特殊字符。可以使用反斜杠来转义字符; --set name=value1\\,value2会变成： name: \"value1,value2\" 同样，也可以转义点序列，这可能在chart中使用toYaml函数解析注释，标签和节点选择器时派上用场 。--set nodeSelector.\"kubernetes.io/role\"=master变为的语法 ： nodeSelector: kubernetes.io/role: master 使用深层嵌套的数据结构可能很难用--set表达。鼓励chart设计师在设计values.yaml文件格式时考虑--set使用情况。 更多的安装方法 helm install命令可以从多个来源安装： 一个chart repository (像上面看到的) 一个本地 chart 压缩包 (helm install foo-0.1.1.tgz) 一个解压后的chart目录 (helm install path/to/foo) 一个完整URL (helm install https://example.com/charts/foo-1.2.3.tgz) 'helm upgrade' and 'helm rollback'：升级版本和失败时恢复 当新版本的chart发布时，或者当你想要更改release配置时，可以使用helm upgrade 命令。 升级需要已有的release并根据提供的信息进行升级。由于Kubernetes chart可能很大而且很复杂，因此Helm会尝试执行最小侵入式升级。它只会更新自上次发布以来发生更改的内容。 $ helm upgrade -f panda.yaml happy-panda stable/mariadb Fetched stable/mariadb-0.3.0.tgz to /Users/mattbutcher/Code/Go/src/k8s.io/helm/mariadb-0.3.0.tgz happy-panda has been upgraded. Happy Helming! Last Deployed: Wed Sep 28 12:47:54 2016 Namespace: default Status: DEPLOYED ... 在上面的例子中，happy-panda release使用相同的chart进行升级，但使用新的YAML文件： mariadbUser: user1 我们可以使用helm get values看看这个新设置是否生效。 $ helm get values happy-panda mariadbUser: user1 该helm get命令是查看集群中的release的有用工具。正如我们上面所看到的，它表明我们的新值 panda.yaml已被部署到群集中。 现在，如果在发布过程中某些事情没有按计划进行，那么使用回滚到以前的版本很容易helm rollback [RELEASE] [REVISION]。 $ helm rollback happy-panda 1 上述回滚我们的“happy-panda”到它的第一个release版本。release版本是增量修订。每次安装，升级或回滚时，修订版本号都会增加1.第一个修订版本号始终为1.我们可以使用helm history [RELEASE]查看特定版本的修订版号。 安装/升级/回滚的有用选项 在安装/升级/回滚期间，可以指定几个其他有用的选项来定制Helm的行为。请注意，这不是cli参数的完整列表。要查看所有参数的说明，请运行 helm --help。 --timeout：等待Kubernetes命令完成的超时时间值（秒），默认值为300（5分钟） --wait：等待所有Pod都处于就绪状态，PVC绑定完，将release标记为成功之前，Deployments有最小（Desired-maxUnavailable）Pod处于就绪状态，并且服务具有IP地址（如果是LoadBalancer，则为Ingress ）。它会等待 --timeout的值。如果达到超时，release将被标记为 FAILED。注意：在部署replicas设置为1 maxUnavailable且未设置为0，作为滚动更新策略的一部分的情况下， --wait它将返回就绪状态，因为它已满足就绪状态下的最小Pod。 --no-hooks：这会跳过命令的运行钩子 --recreate-pods（仅适用于upgrade和rollback）：此参数将导致重新创建所有pod（属于deployment的pod除外） 'helm delete'：删除Release 在需要从群集中卸载或删除release时，请使用以下helm delete命令： $ helm delete happy-panda 这将从集群中删除该release。可以使用以下helm list命令查看当前部署的所有release： $ helm list NAME VERSION UPDATED STATUS CHART inky-cat 1 Wed Sep 28 12:59:46 2016 DEPLOYED alpine-0.1.0 从上面的输出中，我们可以看到该happy-panda release已被删除。 尽快如此，Helm总是保留记录发生了什么。需要查看已删除的版本？helm list --deleted 可显示这些内容，并helm list --all显示了所有release（已删除和当前部署的，以及失败的版本）： ⇒ helm list --all NAME VERSION UPDATED STATUS CHART happy-panda 2 Wed Sep 28 12:47:54 2016 DELETED mariadb-0.3.0 inky-cat 1 Wed Sep 28 12:59:46 2016 DEPLOYED alpine-0.1.0 kindred-angelf 2 Tue Sep 27 16:16:10 2016 DELETED alpine-0.1.0 由于Helm保留已删除release的记录，因此不能重新使用release名称。（如果 确实 需要重新使用此release名称，则可以使用此 --replace参数，但它只会重用现有release并替换其资源。） 请注意，因为release以这种方式保存，所以可以回滚已删除的资源并重新激活它。 'helm repo'：使用存储库 到目前为止，我们一直只从stable存储库repo安装chart。但是可以配置helm使用其他repo。Helm在该helm repo命令下提供了多个repo工具。 可以使用helm repo list以下命令查看配置了哪些repo： $ helm repo list NAME URL stable https://kubernetes-charts.storage.googleapis.com local http://localhost:8879/charts mumoshu https://mumoshu.github.io/charts 新的repo可以通过helm repo add添加： $ helm repo add dev https://example.com/dev-charts 由于chart repo经常更改，因此可以随时通过运行helm repo updat确保Helm客户端处于最新状态。 创建你自己的charts 该chart开发指南Chart Development Guide 介绍了如何开发自己的charts。也可以通过使用以下helm create 命令快速入门： $ helm create deis-workflow Creating deis-workflow 现在有一个chart./deis-workflow。可以编辑它并创建自己的模板。 在编辑chart时，可以通过helm lint验证它是否格式正确。 当将chart打包分发时，可以运行以下 helm package命令： $ helm package deis-workflow deis-workflow-0.1.0.tgz 现在可以通过helm install以下方式轻松安装该chart： $ helm install ./deis-workflow-0.1.0.tgz ... 可以将已归档的chart加载到chart repo中。请参阅chart repo服务器的文档以了解如何上传。 注意：stable repo在Kubernetes Charts GitHub存储库上进行管理。该项目接受chart源代码，并且（在审计后）自动打包。 Tiller，Namespaces和RBAC 在某些情况下，可能希望将Tiller的范围或将多个Tillers部署到单个群集。以下是在这些情况下操作的一些最佳做法。 Tiller可以安装到任何namespace。默认情况下，它安装在kube-system中。可以运行多个Tillers，只要它们各自在自己的namespace中运行。 限制Tiller只能安装到特定的namespace和/或资源类型由Kubernetes RBAC角色和角色绑定控制。可以通过在配置Helm时通过helm init --service-account 向Tiller添加服务帐户。你可以在这里here.找到更多的信息。 Release名称在每个Tiller实例中是唯一的。 chart应该只包含存在于单个命名空间中的资源。 不建议将多个Tillers配置为在相同的命名空间中管理资源。总结 本章介绍了helm客户端的基本使用模式，包括搜索，安装，升级和删除。它也涵盖了有用的工具命令类似如helm status，helm get和 helm repo。 有关这些命令的更多信息，请查看Helm的内置帮助：helm help。 在下一章中，我们将看看开发chart的过程。 Copyright © Mingo 2017-2018 all right reserved，powered by GitbookUpdated at 2018-04-30 18:43:39 "},"quickstart/plugins-zh_cn.html":{"url":"quickstart/plugins-zh_cn.html","title":"插件","keywords":"","body":"插件指南 Helm 2.1.0引入了客户端Helm 插件plugin的概念。插件是一种可以通过helm CLI 访问的工具，但它不是内置Helm代码库的一部分。 现有的插件可以在相关部分related找到或者通过搜索Github。 本指南介绍了如何使用和创建插件。 概述 Helm插件是与Helm无缝集成的附加工具。它们提供了扩展Helm核心功能集的方法，但不需要将每个新功能都通过Go语言写入并添加到核心工具中。 Helm插件具有以下功能： 可以在Helm安装中添加和删除它们，而不会影响核心Helm工具。 它们可以用任何编程语言编写。 他们与Helm集成，并出现在helm help和其他地方。 Helm插件放置在$(helm home)/plugins。 Helm插件模型部分建模在​​Git的插件模型上。为此，有时可能会听到helm称为瓷层 porcelain，插件是管道 plumbing。这是揭示Helm提供用户体验和顶级处理逻辑，而插件则是执行所需操作的“细节工作”的简略说法。 安装插件 使用 $ helm plugin install 命令安装插件。可以将路径设置为本地文件系统上的插件或远程VCS repo的URL。helm plugin install命令克隆或复制该插件的路径/URL到给定的$(helm home)/plugins $ helm plugin install https://github.com/technosophos/helm-template 如果你有一个插件tar分发版，只需将插件解压到 $(helm home)/plugins目录中即可。 您也可以通过直接从URL安装tarball插件helm plugin install http://domain/path/to/plugin.tar.gz 构建插件 在很多方面，插件类似于chart。每个插件都有一个顶级目录，然后是一个plugin.yaml 文件。 $(helm home)/plugins/ |- keybase/ | |- plugin.yaml |- keybase.sh 在上面的例子中，keybase插件包含在名为keybase的目录中。它有两个文件：（plugin.yaml必需）和一个可执行脚本keybase.sh（可选）。 插件的核心是一个简单的YAML文件plugin.yaml。这是一个插件的一个插件YAML，它增加了对Keybase操作的支持： name: \"keybase\" version: \"0.1.0\" usage: \"Integrate Keybase.io tools with Helm\" description: |- This plugin provides Keybase services to Helm. ignoreFlags: false useTunnel: false command: \"$HELM_PLUGIN_DIR/keybase.sh\" name是插件的名称。当Helm执行插件时，这是它将使用的名称（例如，helm NAME将调用此插件）。 name应该匹配目录名称。 在我们上面的例子中，这意味着插件name: keybase应该在一个名为keybase的目录中。 name的限制： name不能一个现有的helm顶级命令重复。 name必须限制为ASCII az，AZ，0-9 _和`-。 version是插件的SemVer 2版本。 usage和description都用于生成命令的帮助文本。 ignoreFlags告诉H​​elm 不会将参数传递给插件。所以，如果一个插件被helm myplugin --foo调用，并且ignoreFlags: true，那么--foo 将被忽略。 useTunnel指示插件需要一个隧道去连接Tiller。这在任何时候插件与Tiller对接都应该设置为true 。它会使Helm打开一个隧道，然后`$TILLER_HOST为该隧道设置正确的本地地址。不用担心：如果Helm由于Tiller在本地运行而检测到隧道是不必啊哟的，它就不会创建隧道。 最后，也是最重要的是，command，是这个插件在调用时会执行的命令。在执行插件之前会插入环境变量。上面的模式说明了指出插件程序所在位置的首选方式。 有一些使用插件命令的策略： 如果插件包含可执行文件command:，则应将可执行文件打包到插件目录中。 command:将在执行前展开任何环境变量。$HELM_PLUGIN_DIR将指向插件目录。 该命令本身不在shell中执行。所以你不能在一个shell脚本上运行。 Helm将大量配置注入到环境变量中。查看环境以查看可用信息。 Helm对插件的语言没有任何设限。你可以用你喜欢的任何方式来写。 命令负责执行具体的帮助文本-h和--help。helm将使用usage和description对helm help和helm help myplugin进行处理，但不会处理helm myplugin --help。 下载器插件 默认情况下，Helm可以使用HTTP/S获取图表。从Helm 2.4.0开始，插件可以从任意源下载chart。 插件应在plugin.yaml文件（顶层）中声明这个特殊功能： downloaders: - command: \"bin/mydownloader\" protocols: - \"myprotocol\" - \"myprotocols\" 如果安装了这样的插件，Helm可以通过调用command指定的协议方案与存储库repo进行交互。特殊存储库应与常规存储库类似添加：特殊存储库helm repo add favorite myprotocol://example.com/ 的规则与常规存储库的规则相同：Helm必须能够下载index.yaml文件以发现并缓存可用charts列表。 定义的命令将使用以下方案调用： command certFile keyFile caFile full-URL。SSL凭证来自存储在$HELM_HOME/repository/repositories.yaml其中的repo定义, 。下载器插件将原始内容转储到stdout并在stderr上报告错误。 环境变量 当Helm执行插件时，它将外部环境传递给插件，并且还会注入一些其他环境变量。 类似KUBECONFIG的变量将为插件设置，如果他们设置在外部环境变量中。 保证以下变量设置： HELM_PLUGIN：插件目录的路径 HELM_PLUGIN_NAME：插件的名称，正如helm所调用的。所以 helm myplug会有简称myplug。 HELM_PLUGIN_DIR：包含该插件的目录。 HELM_BIN：helm命令的路径（由用户执行）。 HELM_HOME：Helm的home的路径。 HELMPATH*：重要Helm文件和目录的路径存储在前缀为HELM_PATH的环境变量中。 TILLER_HOST：Tiller的domain:port。如果创建隧道，则会指向隧道的本地端点。否则，它会指向`$HELM_HOST，--host或默认主机（按照优先级的规则）。 虽然HELM_HOST 可以设置，但不能保证它会指向正确的Tiller实例。这是为了允许插件开发人员在插件本身需要手动配置连接时以其原始状态进行访问HELM_HOST 。 关于 useTunnel 如果插件指定useTunnel: true，Helm将执行以下操作（按顺序）： 解析全局标志和环境 创建隧道 设置TILLER_HOST 执行插件 关闭隧道 command 退出后，隧道即被移除。因此，假定一个进程要使用该隧道，它不能是后台进程，。 关于参数标记解析 在执行插件时，Helm会解析全局标志以供自己使用。其中一些参数标志不会传递给插件。 --debug：如果已指定，$HELM_DEBUG则设为1 --home：这被转换为 $HELM_HOME --host：这被转换为 $HELM_HOST --kube-context：将丢弃。如果你的插件使用useTunnel，这是用来为你设置隧道的。 -h和--help，插件应该显示帮助文本，然后退出。在所有其他情况下，插件可以根据需要使用参数标志。 Copyright © Mingo 2017-2018 all right reserved，powered by GitbookUpdated at 2018-04-30 18:43:40 "},"quickstart/rbac-zh_cn.html":{"url":"quickstart/rbac-zh_cn.html","title":"RBAC","keywords":"","body":"RBAC-基于角色的访问控制 在Kubernetes中，最佳的做法是，为特定的应用程序的服务帐户授予角色,确保应用程序在指定的范围内运行。要详细了解服务帐户权限请阅读官方Kubernetes文档. Bitnami写了一个在集群中配置RBAC的指导，可让你了解RBAC基础知识。 本指南面向希望对Helm限制如下权限的用户: Tiller将资源安装到特定namespace能力 授权Helm客户端对Tiller实例的访问 Tiller和基于角色的访问控制 可以在配置Helm时使用--service-account 参数将服务帐户添加到Tiller 。前提条件是必须创建一个角色绑定，来指定预先设置的角色role和服务帐户service account 名称。 在前提条件下，并且有了一个具有正确权限的服务帐户，就可以像这样运行一个命令来初始化Tiller： helm init --service-account Example: 服务账户带有cluster-admin 角色权限 $ kubectl create serviceaccount tiller --namespace kube-system serviceaccount \"tiller\" created 文件 rbac-config.yaml: apiVersion: v1 kind: ServiceAccount metadata: name: tiller namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRoleBinding metadata: name: tiller roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: tiller namespace: kube-system Note: cluster-admin角色是在Kubernetes集群中默认创建的，因此不必再显式地定义它。. $ kubectl create -f rbac-config.yaml serviceaccount \"tiller\" created clusterrolebinding \"tiller\" created $ helm init --service-account tiller 在特定namespace中部署Tiller，并仅限于在该namespace中部署资源 在上面的例子中，我们让Tiller管理访问整个集群。当然，Tiller正常工作并不一定要为它设置集群管理员访问权限。我们可以指定Role和RoleBinding来将Tiller的范围限制为特定的namespace，而不是指定ClusterRole或ClusterRoleBinding。 $ kubectl create namespace tiller-world namespace \"tiller-world\" created $ kubectl create serviceaccount tiller --namespace tiller-world serviceaccount \"tiller\" created 定义允许Tiller管理namespace tiller-world 中所有资源的角色 ，文件role-tiller.yaml: kind: Role apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: tiller-manager namespace: tiller-world rules: - apiGroups: [\"\", \"extensions\", \"apps\"] resources: [\"*\"] verbs: [\"*\"] $ kubectl create -f role-tiller.yaml role \"tiller-manager\" created 文件 rolebinding-tiller.yaml, kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: tiller-binding namespace: tiller-world subjects: - kind: ServiceAccount name: tiller namespace: tiller-world roleRef: kind: Role name: tiller-manager apiGroup: rbac.authorization.k8s.io $ kubectl create -f rolebinding-tiller.yaml rolebinding \"tiller-binding\" created 之后，运行helm init来在tiller-world namespace中安装Tiller 。 $ helm init --service-account tiller --tiller-namespace tiller-world $HELM_HOME has been configured at /Users/awesome-user/.helm. Tiller (the Helm server side component) has been installed into your Kubernetes Cluster. Happy Helming! $ helm install nginx --tiller-namespace tiller-world --namespace tiller-world NAME: wayfaring-yak LAST DEPLOYED: Mon Aug 7 16:00:16 2017 NAMESPACE: tiller-world STATUS: DEPLOYED RESOURCES: ==> v1/Pod NAME READY STATUS RESTARTS AGE wayfaring-yak-alpine 0/1 ContainerCreating 0 0s Example: 在一个namespace中部署Tiller，并限制它在另一个namespace部署资源 在上面的例子中，我们让Tiller管理它部署所在的namespace。现在，让我们限制Tiller的范围，将资源部署在不同的namespace中！ 下面例子中，让我们在myorg-system namespace中安装Tiller，并允许Tiller在myorg-users namespace中部署资源。 $ kubectl create namespace myorg-system namespace \"myorg-system\" created $ kubectl create serviceaccount tiller --namespace myorg-system serviceaccount \"tiller\" created 在role-tiller.yaml中，定义了一个允许Tiller管理所有myorg-users资源的角色： kind: Role apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: tiller-manager namespace: myorg-users rules: - apiGroups: [\"\", \"extensions\", \"apps\"] resources: [\"*\"] verbs: [\"*\"] $ kubectl create -f role-tiller.yaml role \"tiller-manager\" created 将 service account 与那个role绑定. rolebinding-tiller.yaml, kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: tiller-binding namespace: myorg-users subjects: - kind: ServiceAccount name: tiller namespace: myorg-system roleRef: kind: Role name: tiller-manager apiGroup: rbac.authorization.k8s.io $ kubectl create -f rolebinding-tiller.yaml rolebinding \"tiller-binding\" created 我们还需要授予Tiller访问权限来读取myorg-system中的configmaps，以便它可以存储release信息。如 role-tiller-myorg-system.yaml: kind: Role apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: namespace: myorg-system name: tiller-manager rules: - apiGroups: [\"\", \"extensions\", \"apps\"] resources: [\"configmaps\"] verbs: [\"*\"] $ kubectl create -f role-tiller-myorg-system.yaml role \"tiller-manager\" created 相应的role 绑定. 如 rolebinding-tiller-myorg-system.yaml: kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: tiller-binding namespace: myorg-system subjects: - kind: ServiceAccount name: tiller namespace: myorg-system roleRef: kind: Role name: tiller-manager apiGroup: rbac.authorization.k8s.io $ kubectl create -f rolebinding-tiller-myorg-system.yaml rolebinding \"tiller-binding\" created Helm 和基于角色的访问控制 在pod中运行Helm客户端时，为了让Helm客户端与Tiller实例进行通信，需要授予某些特权。具体来说，Helm客户端需要能够创建pods，转发端口并能够在Tiller运行的namespace中列出pod（这样它才可以找到Tiller）。 Example: 在一个namespace中部署helm，与在另一个namespace中与Tiller交互 在这个例子中，我们将假设Tiller在名为tiller-world 的namespace中运行，并且Helm客户端在helm-world中运行。默认情况下，Tiller在kube-system namespace中运行。 如 helm-user.yaml: apiVersion: v1 kind: ServiceAccount metadata: name: helm namespace: helm-world --- apiVersion: rbac.authorization.k8s.io/v1beta1 kind: Role metadata: name: tiller-user namespace: tiller-world rules: - apiGroups: - \"\" resources: - pods/portforward verbs: - create - apiGroups: - \"\" resources: - pods verbs: - list --- apiVersion: rbac.authorization.k8s.io/v1beta1 kind: RoleBinding metadata: name: tiller-user-binding namespace: tiller-world roleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: tiller-user subjects: - kind: ServiceAccount name: helm namespace: helm-world $ kubectl create -f helm-user.yaml serviceaccount \"helm\" created role \"tiller-user\" created rolebinding \"tiller-user-binding\" created Copyright © Mingo 2017-2018 all right reserved，powered by GitbookUpdated at 2018-04-30 18:43:39 "},"quickstart/securing_installation-zh_cn.html":{"url":"quickstart/securing_installation-zh_cn.html","title":"安全安装","keywords":"","body":"安全安装 Helm是一款强大而灵活的Kubernetes软件包管理和运维工具。使用默认安装命令helm init- 可以快速轻松地安装它和 Tiller，与Helm相对应的服务端组件。 但是，默认安装没有启用任何安全配置。使用这种类型的安装在下面的场景下是完全合适的，在没有安全问题或几乎没有安全问题的群集时可以使用这种安装方式，例如使用Minikube进行本地开发，或者使用在专用网络中，安全性良好且无数据共享或无其他用户或团队。如果是这种情况，那么默认安装很合适，但请记住：权力越大，责任越大。决定使用默认安装时始终要注意相应的安全问题。 谁需要安全配置？ 对于以下类型的集群，我们强烈建议使用正确的安全配置应用于Helm和Tiller，以确保集群，集群中的数据以及它所连接的网络的安全性。 暴露于不受控制的网络环境的群集：不受信任的网络参与者可以访问群集，也可以访问网络环境的不受信任的应用程序。 许多人使用的群集 - 多租户群集 - 作为共享环境 有权访问或使用高价值数据或任何类型网络的群集 通常，像这样的环境被称为 生产等级 或 生产质量 的环境，因为任何因滥用集群而对任何公司造成的损害对于客户，对公司本身或者两者都是深远的。一旦损害风险变得足够高，无论实际风险如何，都需要确保集群的安全完整性。 要为环境正确配置安装，您必须： 了解群集的安全上下文 选择合适的helm安装的最佳实践 以下假定有一个Kubernetes配置文件（一个kubeconfig文件），或者有一个用于访问群集的文件。 了解群集的安全上下文 helm init将Tiller安装到kube-system名称空间中的集群中，而不应用任何RBAC规则。这适用于本地开发和其他私人场景，因为它可以让立即开始工作。它还使你能够继续使用没有基于角色的访问控制（RBAC）支持的Kubernetes群集来运行Helm，直到可以将工作负载移动到更新的Kubernetes版本。 在Tiller安全安装时，需要考虑四个主要方面： 基于角色的访问控制或RBAC Tiller的gRPC端点及Helm的使用情况 Tiller的release信息 Helm harts RBAC Kubernetes的最新版本采用基于角色的访问控制（或RBAC）系统（与现代操作系统一样），以帮助缓解证书被滥用或存在错误时可能造成的损害。即使在身份被劫持的情况下，这个身份在受控空间也只有这么多的权限。这有效地增加了一层安全性，以限制使用该身份进行攻击的范围。 Helm和Tiller在安装，删除和修改逻辑应用程序时，可以包含许多服务交互。因此，它的使用通常涉及整个集群的操作，在多租户集群中意味着Tiller安装必须非常小心才能访问整个集群，以防止不正确的安全活动。 特定用户和团队 - 开发人员，运维人员，系统和网络管理员 - 需要他们自己的群集分区，以便他们可以使用Helm和Tiller，而不会冒着集群其他分区的风险。这需要启用RBAC的Kubernetes集群，并配置Tiller的RBAC权限。有关在Kubernetes中使用RBAC的更多信息，请参阅使用RBAC授权Using RBAC Authorization。 Tiller和用户权限 当前情况下的Tiller不提供将用户凭据映射到Kubernetes内的特定权限的方法。当Tiller在集群内部运行时，它将使用其服务帐户的权限运行。如果没有服务帐户名称提供给Tiller，它将使用该名称空间的默认服务帐户运行。这意味着该服务器上的所有Tiller操作均使用Tiller pod的凭据和权限执行。 为了合适的限制Tiller本身的功能，标准Kubernetes RBAC机制必须配置到Tiller上，包括角色和角色绑定，这些角色明确的限制了Tiller实例可以安装什么以及在哪里安装。 这种情况在未来可能会改变。社区有几种方法可以解决这个问题，采用客户端权限而不是Tiller权限的情况下，活动的权限取决于Pod身份工作组，已经解决了的安全的一般性问题。 Tiller gRPC端点和TLS 在默认安装中，Tiller提供的gRPC端点在集群内部（不在集群外部）可用，不需要应用认证配置。如果不应用身份验证，集群中的任何进程都可以使用gRPC端点在集群内执行操作。在本地或安全的专用群集中，这可以实现快速使用并且是合适的。（当在集群外部运行时，Helm通过Kubernetes API服务器进行身份验证，以达到Tiller，利用现有的Kubernetes身份验证支持。） 共享和生产群集 - 大多数情况下 - 应至少使用Helm 2.7.2，并为每个Tiller gRPC端点配置TLS，以确保群集内gRPC端点的使用仅适用于该端点的正确身份验证标识。这样做可以在任意数量的namespace中部署任意数量的Tiller实例，任何gRPC端点未经授权不可使用。使用Helm init --tiller-tls-verify选择安装启用TLS的Tiller,并验证远程证书，所有其他Helm命令都应该使用该--tls选项。 有关正确配置并使用TLS的Tiller和Helm的正确步骤的更多信息，请参阅Helm和Tiller使用SSLUsing SSL between Helm and Tiller。 当Helm客户端从群集外部连接时，Helm客户端和API服务器之间的安全性由Kubernetes本身管理。你可能需要确保这个链接是安全的。请注意，如果使用上面建议的TLS配置，则Kubernetes API服务器也无法访问客户端和Tiller之间的未加密消息。 Tiller Release信息 由于历史原因，Tiller将其release信息存储在ConfigMaps中。我们建议将默认设置更改为Secrets。 Secrets是Kubernetes用于保存被认为是敏感的配置数据的可接受的方法。尽管secrets本身并不提供很多保护，但Kubernetes集群管理软件经常将它们与其他对象区别开来。因此，我们建议使用secrets来存储release信息。 启用此功能目前需要在Tiller部署时设置参数--storage=secret。这需要直接修改deployment或使用helm init --override=...，因为当前没有helm init 参数可供执行此操作。有关更多信息，请参阅 Using --override。 关于chart 由于Helm的相对生命周期，Helm chart生态系统的发展并没有考虑到整个集群的控制，这在开发人员来说，是完全合理的。但是，chart是一种不仅可以安装可能已经验证或可能未验证的容器的包，它也可以安装到多个namespace中。 与所有共享的软件一样，在受控或共享的环境中，必须在安装之前验证自己安装的所有软件。如果已经通过TLS配置安装了Tiller，并且只有一个或部分namespace的权限，某些chart可能无法安装 - 在这些环境中，这正是你想要的。如果需要使用chart，可能必须与创建者一起工作或自行修改它，以便在应用了适当的RBAC规则的多租户群集中安全地使用它。helm template命令在本地呈现chart并显示输出。 一旦通过检查，可以使用Helm的工具来确保使用的图表的出处和完整性ensure the provenance and integrity of charts。 gRPC工具和安全Tiller配置 许多非常有用的工具直接使用gRPC接口，并且已经针对默认安装构建 - 它们提供了集群范围的访问 - 一旦应用了安全配置后就可能工作不正常。RBAC策略由你或集群运维人员控制，并且可以针对该工具进行调整，或者可以将该工具配置为，在应用于Tiller的特定RBAC策略的约束范围内来正常工作。如果gRPC端点受到保护，则可能需要执行相同的操作：为了使用特定的Tiller实例，这些工具需要自己的安全TLS配置。RBAC策略和gRPC工具一起配置的安全gRPC端点的组合，使你能够按照自己的需要控制群集环境。 Helm和Tiller安全最佳实践 以下指导原则重申了Helm和Tiller安全并正确使用它们的最佳方法。 创建一个启用了RBAC的集群 配置每个Tiller gRPC端点以使用单独的TLS证书 Release信息应该使用Kubernetes Secret 为每个用户，团队或其他具有--service-account参数，role和RoleBindings的组织安装一个Tiller helm init使用--tiller-tls-verify，其他Helm命令--tls来强制验证 如果遵循这些步骤，则helm init命令可能如下所示： $ helm init \\ --tiller-tls \\ --tiller-tls-verify \\ --tiller-tls-cert=cert.pem \\ --tiller-tls-key=key.pem \\ --tls-ca-cert=ca.pem \\ --service-account=accountname 此命令将通过gRPC进行强身份验证，并应用RBAC策略的服务帐户安装启动Tiller。 Copyright © Mingo 2017-2018 all right reserved，powered by GitbookUpdated at 2018-04-28 22:58:50 "},"chart/charts-zh_cn.html":{"url":"chart/charts-zh_cn.html","title":"Charts","keywords":"","body":"Charts Helm使用称为chart的包装格式。chart是描述相关的一组Kubernetes资源的文件集合。单个chart可能用于部署简单的东西，比如memcached pod，或者一些复杂的东西，比如完整的具有HTTP服务，数据库，缓存等的Web应用程序堆栈。 chart通过创建为特定目录树的文件，将它们打包到版本化的压缩包，然后进行部署。 本文档解释了chart格式，提供使用Helm构建chart的基本指导。 Chart文件结构 chart被组织为一个目录内的文件集合。目录名称是chart的名称（没有版本信息）。例如，描述WordPress的chart将被存储在wordpress/目录中。 在这个目录里面，Helm期望如下这样一个的结构的目录树： wordpress/ Chart.yaml # A YAML file containing information about the chart LICENSE # OPTIONAL: A plain text file containing the license for the chart README.md # OPTIONAL: A human-readable README file requirements.yaml # OPTIONAL: A YAML file listing dependencies for the chart values.yaml # The default configuration values for this chart charts/ # A directory containing any charts upon which this chart depends. templates/ # A directory of templates that, when combined with values, # will generate valid Kubernetes manifest files. templates/NOTES.txt # OPTIONAL: A plain text file containing short usage notes Helm保留使用charts/和templates/目录以及上面列出的文件名称。其他文件将被忽略。 Chart.yaml文件 Chart.yaml文件是chart所必需的。它包含以下字段： apiVersion: The chart API version, always \"v1\" (required) name: The name of the chart (required) version: A SemVer 2 version (required) kubeVersion: A SemVer range of compatible Kubernetes versions (optional) description: A single-sentence description of this project (optional) keywords: - A list of keywords about this project (optional) home: The URL of this project's home page (optional) sources: - A list of URLs to source code for this project (optional) maintainers: # (optional) - name: The maintainer's name (required for each maintainer) email: The maintainer's email (optional for each maintainer) url: A URL for the maintainer (optional for each maintainer) engine: gotpl # The name of the template engine (optional, defaults to gotpl) icon: A URL to an SVG or PNG image to be used as an icon (optional). appVersion: The version of the app that this contains (optional). This needn't be SemVer. deprecated: Whether this chart is deprecated (optional, boolean) tillerVersion: The version of Tiller that this chart requires. This should be expressed as a SemVer range: \">2.0.0\" (optional) 如果熟悉Chart.yaml Helm Classic 的文件格式，注意到指定依赖性的字段已被删除。这是因为新的chart使用charts/目录表示依赖关系。 其他字段将被忽略。 Charts和版本控制 每个chart都必须有一个版本号。版本必须遵循SemVer 2标准。与Helm Class 格式不同，Kubernetes Helm使用版本号作为发布标记。存储库中的软件包由名称加版本识别。 例如，nginx version字段设置为1.2.3将被命名为： nginx-1.2.3.tgz 更复杂的SemVer 2命名也是支持的，例如 version: 1.2.3-alpha.1+ef365。但非SemVer命名是明确禁止的。 注意：虽然Helm Classic和Deployment Manager在chart方面都非常适合GitHub，但Kubernetes Helm并不依赖或需要GitHub甚至Git。因此，它不使用Git SHA进行版本控制。 许多Helm工具都使用Chart.yaml的version字段，其中包括CLI和Tiller服务。在生成包时，helm package命令将使用它在Chart.yaml中的版本名作为包名。系统假定chart包名称中的版本号与Chart.yaml中的版本号相匹配。不符合这个情况会导致错误。 appVersion字段 请注意，appVersion字段与version字段无关。这是一种指定应用程序版本的方法。例如，drupal chart可能有一个appVersion: 8.2.1，表示chart中包含的Drupal版本（默认情况下）是8.2.1。该字段是信息标识，对chart版本没有影响。 弃用charts 在管理chart tepo库中的chart时，有时需要弃用chart。Chart.yaml的deprecated字段可用于将chart标记为已弃用。如果存储库中最新版本的chart标记为已弃用，则整个chart被视为已弃用。chart名称稍后可以通过发布未标记为已弃用的较新版本来重新使用。废弃chart的工作流程根据kubernetes/charts 项目的工作流程如下： 更新chart的Chart.yaml以将chart标记为启用，并且更新版本 在chart Repository中发布新的chart版本 从源代码库中删除chart（例如git） Chart许可证文件，自述文件和说明文件 chart还可以包含描述chart的安装，配置，使用和许可证的文件。chart的自述文件应由Markdown（README.md）语法格式化，并且通常应包含： chart提供的应用程序或服务的描述 运行chart的任何前提条件或要求 选项values.yaml和默认值的说明 任何其他可能与安装或配置chart相关的信息 chart还可以包含一个简短的纯文本templates/NOTES.txt文件，在安装后以及查看版本状态时将打印出来。此文件将作为模板template进行评估 ，并可用于显示使用说明，后续步骤或任何其他与发布chart相关的信息。例如，可以提供用于连接到数据库或访问Web UI的指令。由于运行时，该文件被打印到标准输出 helm install或helm status，建议保持内容简短并把更多细节指向自述文件。 Chart依赖关系 在Helm中，一个chart可能依赖于任何数量的其他chart。这些依赖关系可以通过requirements.yaml 文件动态链接或引入charts/目录并手动管理。 虽然有一些团队需要手动管理依赖关系的优势，但声明依赖关系的首选方法是使用 chart 内部的requirements.yaml文件。 注意： 传统Helm 的Chart.yaml dependencies:部分字段已被完全删除弃用。 用requirements.yaml来管理依赖关系 requirements.yaml文件是列出chart的依赖关系的简单文件。 dependencies: - name: apache version: 1.2.3 repository: http://example.com/charts - name: mysql version: 3.2.1 repository: http://another.example.com/charts 该name字段是chart的名称。 version字段是chart的版本。 repository字段是chart repo的完整URL。请注意，还必须使用helm repo add添加该repo到本地才能使用。 有了依赖关系文件，你可以通过运行helm dependency update ，它会使用你的依赖关系文件将所有指定的chart下载到你的charts/目录中。 $ helm dep up foochart Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the \"local\" chart repository ...Successfully got an update from the \"stable\" chart repository ...Successfully got an update from the \"example\" chart repository ...Successfully got an update from the \"another\" chart repository Update Complete. Happy Helming! Saving 2 charts Downloading apache from repo http://example.com/charts Downloading mysql from repo http://another.example.com/charts 当helm dependency update检索chart时，它会将它们作为chart存档存储在charts/目录中。因此，对于上面的示例，可以在chart目录中看到以下文件： charts/ apache-1.2.3.tgz mysql-3.2.1.tgz 通过requirements.yaml管理chart是一种轻松更新chart的好方法，还可以在整个团队中共享requirements信息。 requirements.yaml中的alias字段 除上述其他字段外，每个requirement条目可能包含可选字段alias。 为依赖的chart添加别名会将chart放入依赖关系中，并使用别名作为新依赖关系的名称。 如果需要使用其他名称访问chart，可以使用alias。 # parentchart/requirements.yaml dependencies: - name: subchart repository: http://localhost:10191 version: 0.1.0 alias: new-subchart-1 - name: subchart repository: http://localhost:10191 version: 0.1.0 alias: new-subchart-2 - name: subchart repository: http://localhost:10191 version: 0.1.0 在上面的例子中，我们将得到parentchart的3个依赖关系 subchart new-subchart-1 new-subchart-2 实现这一目的的手动方法是charts/中用不同名称多次复制/粘贴目录中的同一chart 。 requirements.yaml中的tags和condition字段 除上述其他字段外，每个需求条目可能包含可选字段tags和condition。 所有charts都会默认加载。如果存在tags或condition字段，将对它们进行评估并用于控制应用的chart的加载。 Condition - condition 字段包含一个或多个YAML路径（用逗号分隔）。如果此路径存在于顶级父级的值中并且解析为布尔值，则将根据该布尔值启用或禁用chart。只有在列表中找到的第一个有效路径才被评估，如果没有路径存在，那么该条件不起作用。 Tags - 标签字段是与此chart关联的YAML标签列表。在顶级父级的值中，可以通过指定标签和布尔值来启用或禁用所有带有标签的chart。 # parentchart/requirements.yaml dependencies: - name: subchart1 repository: http://localhost:10191 version: 0.1.0 condition: subchart1.enabled, global.subchart1.enabled tags: - front-end - subchart1 - name: subchart2 repository: http://localhost:10191 version: 0.1.0 condition: subchart2.enabled,global.subchart2.enabled tags: - back-end - subchart2 # parentchart/values.yaml subchart1: enabled: true tags: front-end: false back-end: true 在上面的示例中，所有带有标签的front-end的charts都将被禁用，但由于 subchart1.enabled的值在父项值中为“真”，因此条件将覆盖该 front-end标签，subchart1会启用。 由于subchart2被标记back-end和标签的计算结果为true，subchart2将被启用。还要注意的是，虽然subchart2有一个在requirements.yaml中指定的条件，但父项的值中没有对应的路径和值，因此条件无效。 使用命令行时带有tag和conditions --set参数可使用来更改tag和conditions值。 helm install --set tags.front-end=true --set subchart2.enabled=false tags和conditions解析 Conditions (设置 values) 会覆盖tags配置.。第一个存在的condition路径生效，后续该chart的condition路径将被忽略。 如果chart的某tag的任一tag的值为true，那么该tag的值为true，并启用这个chart。 Tags 和 conditions值必须在顶级父级的值中进行设置。 tags:值中的关键字必须是顶级关键字。目前不支持全局和嵌套tags:表格。 通过requirements.yaml导入子值 在某些情况下，希望允许子chart的值传到父chart并作为通用默认值共享。使用这种exports格式的另一个好处是它可以使未来的工具能够考虑用户可设置的值。 要导入的值的键可以在父chart文件中requirements.yaml使用YAML list指定。list中的每个项目都是从子chart exports字段导入的key。 要导入不包含在exports key中的值，请使用子父级child-parent格式。下面描述了两种格式的例子。 使用exports格式 如果子chart的values.yaml文件exports在根目录中包含一个字段，则可以通过指定要导入的关键字将其内容直接导入到父项的值中，如下例所示： # parent's requirements.yaml file ... import-values: - data # child's values.yaml file ... exports: data: myint: 99 由于我们在导入列表中指定了data键，因此Helm会在exports子图的字段中查找data键并导入其内容。 最终的父值将包含我们的导出字段： # parent's values file ... myint: 99 请注意，父键data不包含在父chart的最终值中。如果需要指定父键，请使用'child-parent'格式。 使用child-parent格式 要访问未包含在子chart键值exports的中的值，需要指定要导入的值的源键（child）和父chart值（parent）中的目标路径。 下面的例子中的import-values告诉Helm去拿在child:路径发现的任何值，并将其复制到父值parent:指定的路径 # parent's requirements.yaml file dependencies: - name: subchart1 repository: http://localhost:10191 version: 0.1.0 ... import-values: - child: default.data parent: myimports 在上面的例子中，在subchart1default.data的值中找到的值将被导入到父chart值中myimports的键值，详细如下： # parent's values.yaml file myimports: myint: 0 mybool: false mystring: \"helm rocks!\" # subchart1's values.yaml file default: data: myint: 999 mybool: true 父chart的结果值为： # parent's final values myimports: myint: 999 mybool: true mystring: \"helm rocks!\" 父chart的最终值现在包含从subchart1导入的myint和mybool字段。 通过charts/目录手动管理依赖性 如果需要更多的控制依赖关系，可以通过将依赖的charts复制到charts/目录中来明确表达这些依赖关系 。 依赖关系可以是chart归档（foo-1.2.3.tgz）或解压缩的chart目录。但它的名字不能从_或.开始。这些文件被chart加载器忽略。 例如，如果WordPress chart依赖于Apache chart，则在WordPress chart的charts/目录中提供（正确版本的）Apache chart： wordpress: Chart.yaml requirements.yaml # ... charts/ apache/ Chart.yaml # ... mysql/ Chart.yaml # ... 上面的示例显示了WordPress chart如何通过在其`charts/``目录中包含这些charts来表示它对Apache和MySQL的依赖关系。 提示： 将依赖项放入您的charts/目录，请使用helm fetch命令 使用依赖关系的操作方面影响 上面的部分解释了如何指定chart依赖关系，但是这会如何影响使用helm install和helm upgrade的chart安装？ 假设名为“A”的chart创建以下Kubernetes对象 namespace \"A-Namespace\" statefulset \"A-StatefulSet\" service \"A-Service\" 此外，A依赖于创建对象的chart B. namespace \"B-Namespace\" replicaset \"B-ReplicaSet\" service \"B-Service\" 安装/升级chart A后，会创建/修改单个Helm版本。该版本将按以下顺序创建/更新所有上述Kubernetes对象： A-Namespace B-Namespace A-StatefulSet B-ReplicaSet A-Service B-Service 这是因为当Helm安装/升级charts时，charts中的Kubernetes对象及其所有依赖项都是如下 聚合成一个单一的集合; 然后 按类型排序，然后按名称排序; 接着 按该顺序创建/更新。 因此，单个release是使用charts及其依赖关系创建的所有对象。 Kubernetes类型的安装顺序由kind_sorter.go中的枚举InstallOrder给出（the Helm source file)）。 模板Templates和值Values Helm chart模板是用Go模板语言Go template language编写的 ，其中添加了来自Sprig库from the Sprig library的50个左右的附加模板函数以及一些其他专用函数specialized functions。 所有模板文件都存储在chart的templates/文件夹中。当Helm渲染charts时，它将通过模板引擎传递该目录中的每个文件。 模板的值有两种提供方法： chart开发人员可能会在chart内部提供一个values.yaml文件。该文件可以包含默认值。 chart用户可能会提供一个包含值的YAML文件。这可以通过命令行提供helm install -f。 当用户提供自定义值时，这些值将覆盖chart中values.yaml文件中的值。 模板文件 模板文件遵循用于编写Go模板的标准约定（请参阅文本/模板Go包文档 以了解详细信息）。示例模板文件可能如下所示： apiVersion: v1 kind: ReplicationController metadata: name: deis-database namespace: deis labels: heritage: deis spec: replicas: 1 selector: app: deis-database template: metadata: labels: app: deis-database spec: serviceAccount: deis-database containers: - name: deis-database image: {{.Values.imageRegistry}}/postgres:{{.Values.dockerTag}} imagePullPolicy: {{.Values.pullPolicy}} ports: - containerPort: 5432 env: - name: DATABASE_STORAGE value: {{default \"minio\" .Values.storage}} 上面的示例基于此网址，是Kubernetes replication controller的模板。它可以使用以下四个模板值（通常在values.yaml文件中定义 ）： imageRegistry：Docker镜像的源。 dockerTag：docker镜像的标签。 pullPolicy：Kubernetes镜像拉取策略。 storage：存储后端，其默认设置为 \"minio\" 所有这些值都由模板作者定义。Helm不需要或指定参数。 要查更多charts，请查看Kubernetes charts项目 预定义值 通过values.yaml文件（或通过--set 标志）提供的值可以从.Values模板中的对象访问。可以在模板中访问其他预定义的数据片段。 以下值是预定义的，可用于每个模板，并且不能被覆盖。与所有值一样，名称区分大小写。 Release.Name：release的名称（不是chart） Release.Time：chart版本上次更新的时间。这将匹配Last Released发布对象上的时间。 Release.Namespace：chart release发布的namespace。 Release.Service：进行发布的服务。通常是Tiller。 Release.IsUpgrade：如果当前操作是升级或回滚，则设置为true。 Release.IsInstall：如果当前操作是安装，则设置为true。 Release.Revision：版本号。它从1开始，并随着每个helm upgrade增加。 Chart：Chart.yaml的内容。chart版本可以从Chart.Version和维护人员 Chart.Maintainers一起获得。 Files：包含chart中所有非特殊文件的map-like对象。不会允许你访问模板，但会让你访问存在的其他文件（除非它们被排除使用.helmignore）。可以使用{{index .Files \"file.name\"}}或使用{{.Files.Get name}}或 {{.Files.GetString name}}功能来访问文件。也可以使用{{.Files.GetBytes}}访问该文件的内容[byte] Capabilities：包含有关Kubernetes版本信息的map-like对象（{{.Capabilities.KubeVersion}}，Tiller（{{.Capabilities.TillerVersion}}和支持的Kubernetes API版本（{{.Capabilities.APIVersions.Has \"batch/v1\"}}） 注意: 任何未知的Chart.yaml字段将被删除。它们不会在chart对象内部被访问。因此，Chart.yaml不能用于将任意结构化的数据传递到模板中。values文件可以用于传递。 值values文件 考虑到上一节中的模板values.yaml，提供了如下必要值的信息： imageRegistry: \"quay.io/deis\" dockerTag: \"latest\" pullPolicy: \"Always\" storage: \"s3\" values文件是YAML格式的。chart可能包含一个默认 values.yaml文件。Helm install命令允许用户通过提供额外的YAML值来覆盖值： $ helm install --values=myvals.yaml wordpress 当以这种方式传递值时，它们将被合并到默认values文件中。例如，考虑一个如下所示的myvals.yaml文件： storage: \"gcs\" 当它与chart中values.yaml的内容合并时，生成的内容将为： imageRegistry: \"quay.io/deis\" dockerTag: \"latest\" pullPolicy: \"Always\" storage: \"gcs\" 注意只有最后一个字段被覆盖了，其他的不变。 注：包含在chart内的默认values文件必须命名 values.yaml。但是在命令行上指定的文件可以被命名为任何名称。 注：如果在helm install或helm upgrade使用--set，则这些值仅在客户端转换为YAML。 注意：如果values文件中存在任何必需的条目，则可以使用'required'功能'required' function在chart模板中声明它们 然后可以在模板内部访问任何这些.Values对象值 ： apiVersion: v1 kind: ReplicationController metadata: name: deis-database namespace: deis labels: heritage: deis spec: replicas: 1 selector: app: deis-database template: metadata: labels: app: deis-database spec: serviceAccount: deis-database containers: - name: deis-database image: {{.Values.imageRegistry}}/postgres:{{.Values.dockerTag}} imagePullPolicy: {{.Values.pullPolicy}} ports: - containerPort: 5432 env: - name: DATABASE_STORAGE value: {{default \"minio\" .Values.storage}} 范围Scope，依赖Dependencies和值Values values文件可以声明顶级chart的值，也可以为chart的charts/目录中包含的任何chart声明值。或者，用不同的方式来描述它，values文件可以为chart及其任何依赖项提供值。例如，上面的演示WordPresschart具有mysql和apache依赖性。values文件可以为所有这些组件提供值： title: \"My WordPress Site\" # Sent to the WordPress template mysql: max_connections: 100 # Sent to MySQL password: \"secret\" apache: port: 8080 # Passed to Apache 更高级别的chart可以访问下面定义的所有变量。所以WordPresschart可以访问MySQL密码 .Values.mysql.password。但较低级别的chart无法访问父chart中的内容，因此MySQL将无法访问该title属性。同样的，也不能访问apache.port。 值是命名空间限制的，但命名空间已被修剪。因此对于WordPresschart来说，它可以访问MySQL密码字段.Values.mysql.password。但是对于MySQL chart来说，这些值的范围已经减小了，并且删除了名namespace前缀，所以它会将密码字段简单地视为 .Values.password。 全局值 从2.0.0-Alpha.2开始，Helm支持特殊的“全局”值。考虑前面例子的这个修改版本： 标题：“我的WordPress网站” ＃发送到WordPress模板 title: \"My WordPress Site\" # Sent to the WordPress template global: app: MyWordPress mysql: max_connections: 100 # Sent to MySQL password: \"secret\" apache: port: 8080 # Passed to Apache 上面添加了一个global区块，值app: MyWordPress。此值可供所有chart使用.Values.global.app。 比如，该mysql模板可以访问app如{{.Values.global.app}}，apache chart也同样的。上面的values文件是这样高效重新生成的： title: \"My WordPress Site\" # Sent to the WordPress template global: app: MyWordPress mysql: global: app: MyWordPress max_connections: 100 # Sent to MySQL password: \"secret\" apache: global: app: MyWordPress port: 8080 # Passed to Apache 这提供了一种与所有子chart共享一个顶级变量的方法，这对设置metadata中像标签这样的属性很有用。 如果子chart声明了一个全局变量，则该全局将向下传递 （到子chart的子chart），但不向上传递到父chart。子chart无法影响父chart的值。 此外，父chart的全局变量优先于子chart中的全局变量。 参考 当涉及到编写模板和values文件时，有几个标准参考可以帮助你。 Go templates Extra template functions The YAML format 使用Helm管理chart 该helm工具有几个用于处理chart的命令。 它可以为你创建一个新的chart： $ helm create mychart Created mychart/ 编辑完chart后，helm可以将其打包到chart压缩包中： $ helm package mychart Archived mychart-0.1.-.tgz 您可以用helm来帮助查找chart格式或信息的问题： $ helm lint mychart No issues found Chart repo库 chart repo库是容纳一个或多个封装的chart的HTTP服务器。虽然helm可用于管理本地chart目录，但在共享chart时，首选机制是chart repo库。 任何可以提供YAML文件和tar文件并可以回答GET请求的HTTP服务器都可以用作repo库服务器。 Helm附带用于开发人员测试的内置服务器（helm serve）。Helm团队测试了其他服务器，包括启用了网站模式的Google Cloud Storage以及启用了网站模式的S3。 repo库的主要特征是存在一个名为的特殊文件index.yaml，它具有repo库提供的所有软件包的列表以及允许检索和验证这些软件包的元数据。 在客户端，repo库使用helm repo命令进行管理。但是，Helm不提供将chart上传到远程存储服务器的工具。这是因为这样做会增加部署服务器的需求，从而增加配置repo库的难度。 Chart 起始包 helm create命令采用可选--starter选项，可以指定“起始chart”。 起始chart只是普通的chart，位于$HELM_HOME/starters。作为chart开发人员，可以创作专门设计用作起始的chart。记住这些chart时应考虑以下因素： Chart.yaml将被生成器覆盖。 用户将期望修改这样的chart内容，因此文档应该指出用户如何做到这一点。 所有匹配项将被替换为指定的chart名称，以便起始chart可用作模板。 目前添加chart的唯一方法是手动将其复制到$HELM_HOME/starters。在chart的文档中，你需要解释该过程。 Copyright © Mingo 2017-2018 all right reserved，powered by GitbookUpdated at 2018-04-30 18:42:17 "},"chart/charts_hooks-zh_cn.html":{"url":"chart/charts_hooks-zh_cn.html","title":"Hooks","keywords":"","body":"Hooks Helm提供了一个hook机制，允许chart开发人员在release的生命周期中的某些点进行干预。例如，可以使用hooks来： 在加载任何其他chart之前，在安装过程中加载ConfigMap或Secret。 在安装新chart之前执行作业以备份数据库，然后在升级后执行第二个作业以恢复数据。 在删除release之前运行作业，以便在删除release之前优雅地停止服务。 Hooks像常规模板一样工作，但它们具有特殊的注释，可以使Helm以不同的方式使用它们。在本节中，我们介绍Hooks的基本使用模式。 可用的Hooks 定义了以下hooks： 预安装pre-install:：在模板渲染后执行，但在Kubernetes中创建任何资源之前执行。 安装后post-install：在所有资源加载到Kubernetes后执行 预删除pre-delete：在从Kubernetes删除任何资源之前执行删除请求。 删除后post-delete：删除所有release的资源后执行删除请求。 升级前pre-upgrade：在模板渲染后，但在任何资源加载到Kubernetes之前执行升级请求（例如，在Kubernetes应用操作之前）。 升级后post-upgrade：在所有资源升级后执行升级。 预回滚pre-rollback：在渲染模板之后，但在任何资源已回滚之前，在回滚请求上执行。 回滚后post-rollback：在修改所有资源后执行回滚请求。 Hooks和release的生命周期 Hooks让chart开发人员有机会在release的生命周期中的关键点执行操作。例如，考虑a的生命周期。默认情况下，生命周期如下所示： 用户运行 helm install foo chart被加载到Tiller中 经过一些验证后，Tiller渲染foo模板 Tiller将产生的资源加载到Kubernetes中 Tiller将release名称（和其他数据）返回给客户端 客户端退出 Helm为install生命周期定义了两个hook：pre-install和 post-install。如果foo chart的开发者实现了两个hook，那么生命周期就像这样改变： 用户运行 helm install foo chart被加载到Tiller中 经过一些验证后，Tiller渲染foo模板 Tiller准备执行pre-install hook（将hook资源加载到Kubernetes中） Tiller会根据权重对hook进行排序（默认分配权重0），并按相同权重的hook按升序排序。 Tiller然后装载最低权重的hook（从负到正） Tiller等待，直到hook“准备就绪” Tiller将产生的资源加载到Kubernetes中。请注意，如果设置--wait标志，Tiller将等待，直到所有资源都处于就绪状态，并且在准备就绪之前不会运行post-installhook。 Tiller执行post-install hook（加载hook资源） Tiller等待，直到hook“准备就绪” Tiller将release名称（和其他数据）返回给客户端 客户端退出 等到hook准备就绪是什么意思？这取决于在hook中声明的资源。如果资源是Job者一种资源，Tiller将等到作业成功完成。如果作业失败，则发布失败。这是一个阻塞操作，所以Helm客户端会在Job运行时暂停。 对于所有其他类型，只要Kubernetes将资源标记为加载（添加或更新），资源就被视为“就绪”。当一个hook声明了很多资源时，这些资源将被串行执行。如果他们有hook权重（见下文），他们按照加权顺序执行。否则，订购过程不能保证。（在Helm 2.3.0及之后的版本中，它们按字母顺序排列，但这种行为并未被视为具有约束力，将来可能会发生变化）。添加挂钩权重被认为是很好的做法，并将其设置为0如果权重不是重要。 Hook资源不与相应的release一起进行管理 Hook创建的资源不作为release的一部分进行跟踪或管理。一旦Tiller验证hook已经达到其就绪状态，它将hook资源放在一边。 实际上，这意味着如果在hook中创建资源，则不能依赖于helm delete删除资源。要销毁这些资源，需要编写代码在pre-delete 或post-deletehook中执行此操作，或者将\"helm.sh/hook-delete-policy\"注释添加到hook模板文件。 写一个hook Hook只是Kubernetes manifest文件，在metadata部分有特殊的注释 。因为他们是模板文件，可以使用所有的Normal模板的功能，包括读取.Values，.Release和.Template。 例如，在此模板中,存储在templates/post-install-job.yaml的声明要在post-install阶段运行作业： apiVersion: batch/v1 kind: Job metadata: name: \"{{.Release.Name}}\" labels: heritage: {{.Release.Service | quote }} release: {{.Release.Name | quote }} chart: \"{{.Chart.Name}}-{{.Chart.Version}}\" annotations: # This is what defines this resource as a hook. Without this line, the # job is considered part of the release. \"helm.sh/hook\": post-install \"helm.sh/hook-weight\": \"-5\" \"helm.sh/hook-delete-policy\": hook-succeeded spec: template: metadata: name: \"{{.Release.Name}}\" labels: heritage: {{.Release.Service | quote }} release: {{.Release.Name | quote }} chart: \"{{.Chart.Name}}-{{.Chart.Version}}\" spec: restartPolicy: Never containers: - name: post-install-job image: \"alpine:3.3\" command: [\"/bin/sleep\",\"{{default \"10\" .Values.sleepyTime}}\"] 注释使这个模板成为hook： annotations: \"helm.sh/hook\": post-install 一个资源可以部署多个hook： annotations: \"helm.sh/hook\": post-install,post-upgrade 同样，实现一个给定的hook的不同种类资源数量没有限制。例如，我们可以将secret和config map声明为预安装hook。 子chart声明hook时，也会评估这些hook。顶级chart无法禁用子chart所声明的hook。 可以为一个hook定义一个权重，这将有助于建立一个确定性的执行顺序。权重使用以下注释来定义： annotations: \"helm.sh/hook-weight\": \"5\" hook权重可以是正数或负数，但必须表示为字符串。当Tiller开始执行一个特定类型的hook的执行周期时，它会按升序对这些hook进行排序。 还可以定义确定何时删除相应的hook资源的策略。hook删除策略使用以下注释来定义： annotations: \"helm.sh/hook-delete-policy\": hook-succeeded 可以选择一个或多个定义的注释值： \"hook-succeeded\" 指定Tiller应该在hook成功执行后删除hook。 \"hook-failed\" 指定如果hook在执行期间失败，Tiller应该删除hook。 \"before-hook-creation\" 指定Tiller应在删除新hook之前删除以前的hook。 自动删除以前版本的hook 当helm 的release更新时，有可能hook资源已经存在于群集中。默认情况下，helm会尝试创建资源，并抛出错误\"... already exists\"。 我们可以选择\"helm.sh/hook-delete-policy\": \"before-hook-creation\"，取代 \"helm.sh/hook-delete-policy\": \"hook-succeeded,hook-failed\"因为： 例如为了手动调试，将错误的hook作业资源保存在kubernetes中是很方便的。 出于某种原因，可能有必要将成功的hook资源保留在kubernetes中。 同时，在helm release升级之前进行手动资源删除是不可取的。 \"helm.sh/hook-delete-policy\": \"before-hook-creation\" 在hook中的注释，如果在新的hook启动前有一个hook的话，会使Tiller将以前的release中的hook删除，，而这个hook同时它可能正在被其他一个策略使用。 Copyright © Mingo 2017-2018 all right reserved，powered by GitbookUpdated at 2018-04-30 18:25:20 "}}